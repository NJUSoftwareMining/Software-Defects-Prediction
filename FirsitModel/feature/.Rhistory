return (sum * 4 * (b-a)/16/90);
}
culfunc1_simple <- function(a,b){
h = (b-a)/16;
x <- a:h:b;
sum = 0;
for(i in 2:15){
sum += 32 * func1(x(i)-0.75,2) + 12 * func1(x(i)-0.5,2) + 32 * func1(x(i)-0.25,2) + 14 * func1(x(i),2)
}
sum += 7 * func1(a,2) + 7 * func1(b,2) + 32 * func1(x(16)-0.75,2) + 12 * func1(x(16)-0.5,2) + 32 * func1(x(16)-0.25,2)
return (sum * 4 * (b-a)/16/90);
culfunc1_simple <- function(a,b){
h = (b-a)/16;
x <- a:h:b;
sum = 0;
for(i in 2:15){
sum += 32 * func1(x(i)-0.75,2) + 12 * func1(x(i)-0.5,2) + 32 * func1(x(i)-0.25,2) + 14 * func1(x(i),2)
}
sum += 7 * func1(a,2) + 7 * func1(b,2) + 32 * func1(x(16)-0.75,2) + 12 * func1(x(16)-0.5,2) + 32 * func1(x(16)-0.25,2)
culfunc1_simple <- function(a,b){
h = (b-a)/16;
x <- a:h:b;
sum = 0;
for(i in 2:15){
sum = sum + 32 * func1(x(i)-0.75,2) + 12 * func1(x(i)-0.5,2) + 32 * func1(x(i)-0.25,2) + 14 * func1(x(i),2)
}
sum = sum + 7 * func1(a,2) + 7 * func1(b,2) + 32 * func1(x(16)-0.75,2) + 12 * func1(x(16)-0.5,2) + 32 * func1(x(16)-0.25,2)
return (sum * 4 * (b-a)/16/90);
}
culfunc1_simple(0,1)
x <- a:h:b;
x <- 0:0.1:1;
x
0:0.1:1
0: 0.01 :1
0: 0.01 :20
0: 0.01 :20
0 : 0.005 :10
?seq
seq(0,1,0.01)
culfunc1_simple <- function(a,b){
h = (b-a)/16;
x <- seq(a,b,h);
sum = 0;
for(i in 2:15){
sum = sum + 32 * func1(x(i)-0.75,2) + 12 * func1(x(i)-0.5,2) + 32 * func1(x(i)-0.25,2) + 14 * func1(x(i),2)
}
sum = sum + 7 * func1(a,2) + 7 * func1(b,2) + 32 * func1(x(16)-0.75,2) + 12 * func1(x(16)-0.5,2) + 32 * func1(x(16)-0.25,2)
return (sum * 4 * (b-a)/16/90);
}
culfunc1_simple(0,1)
x
x <- seq(0,1,0.001)
x
x(1)
x[1]
x[2]
culfunc1_simple <- function(a,b){
h = (b-a)/16;
x <- seq(a,b,h);
sum = 0;
for(i in 2:15){
sum = sum + 32 * func1(x[i]-0.75,2) + 12 * func1(x[i]-0.5,2) + 32 * func1(x[i]-0.25,2) + 14 * func1(x[i],2)
}
sum = sum + 7 * func1(a,2) + 7 * func1(b,2) + 32 * func1(x[16]-0.75,2) + 12 * func1(x[16]-0.5,2) + 32 * func1(x[16]-0.25,2)
return (sum * 4 * (b-a)/16/90);
}
culfunc1_simple(0,1)
culfunc1_simple(0,2)
func1<-function(x,b) {
return (b^x/factorial(x)*exp(-b))
}
func1<-function(x,b) {
return (x^2)
}
culfunc1_simple(0,1)
func1<-function(x,b) {
+     return (x^2)
+ }
func1<-function(x,b) {     return (x^2;)}
func1(4)
culfunc1_simple(0,1)
culfunc1_simple(0,2)
Accumulate<-function(x0,y0,x1,y1){
sum = 0;
x<-seq(f=x0,t=x1,0.05)
y<-seq(f=y0,t=y1,0.1)
z<-outer(x,y,g);
sum(z);
}
Accumulate(0,-1,2,1)
Accumulate(0,-1,2,1)
Accumulate<-function(x0,y0,x1,y1){
sum = 0;
x<-seq(f=x0,t=x1,0.005)
y<-seq(f=y0,t=y1,0.01)
z<-outer(x,y,g);
sum(z);
}
Accumulate(0,-1,2,1)
Accumulate(0,-5,5,5)
Accumulate(0,-5,2,5)
Accumulate(2,-5,4,5)
Accumulate(4,-5,6,5)
Accumulate(0,-5,6,5)
Accumulate(0,-5,2,5)/Accumulate(2,-5,4,5)
Accumulate(0,-5,2,5)/Accumulate(0,-5,6,5)
Accumulate(0,-5,2,0)/Accumulate(0,-5,6,5)
Accumulate(2,-5,4,0)/Accumulate(0,-5,6,5)
Accumulate(4,-5,6,0)/Accumulate(0,-5,6,5)
Accumulate(4,-5,6,0)/Accumulate(0,-5,6,5)
？P-value
?P-value
?qt
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(x~y)
sumcoef(fit)
summary(fit)$coefficients
beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)
e<-y-beta0-beta1*x
sigma<-sqrt(sum(e^2)/(n-2))
n<-9
beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(y)-beta1*mean(x)
e<-y-beta0-beta1*x
sigma<-sqrt(sum(e^2)/(n-2))
mcars
mtcars
mtcars
fit2 <- lm(weight~mpg,data = mtcars)
fit2 <- lm(wt~mpg,data = mtcars)
sumCoef<-summary(fit2)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[2,2]
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[1,2]
sumCoef[1,1]
sumCoef[2,1]
sumCoef
sumCoef[1,1]+c(-1,1)*qt(.975,df=fit2$df)*sumCoef[1,2]
fit2 <- lm(wt~mpg,data = mtcars)
sumCoef<-summary(fit2)$coefficients
sumCoef
?summary
?lm
fit2
beat1 <- -0.1409
beat0 <- -6.0473
x <- c(1,2,3)
beta0-beta1*x
beat0 <- 6.0473
beta0-beta1*x
beat0-beat1*x
summary(fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
f <- lm(y ~ x)
summary(f) # p-value: 0.05296
# Problem 2.
summary(f) # Residual standard error: 0.223 on 7 degrees of freedom
x
y
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(x~y)
summary(fit)
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
predict(fit,data.frame(x=mean(x)), interval="confidence")
fit3 <- lm(mpg~I(wt*1000),data = mtcars)
predict(fit3,data.frame(x=mean(x)), interval="confidence")
(3, 3, 4,4,4,3,3,2)
c(3, 3, 4,4,4,3,3,2)
x <- c(3 3 4 4 4 3 3 2)
x <- (3, 3, 4,4,4,3,3,2)
x <- c(3, 3, 4,4,4,3,3,2)
y <- c(90,84,81,84,78,88,95,85)
x'
d
trans(x)
t(x)
x*t(y)
t(x)*y
x*y
x *t(y)
x %*% t(y)
t(x) %*% y
sum(x)
2213/sum(x)
2213/sum(x)/20
shuttle
library(MASS)
?shuttle
shuttle
shuttle$newUse <- as.numeric(shuttle$use == "auto")
fit <- glm(newUse ~ as.factor(wind) - 1, data=shuttle, family="binomial")
odds <- exp(summary(fit)$coef)
odds
odds[1]
odds[2]
odds[1]/odds[2]
?binomial
# Problem 2.
fit <- glm(newUse ~ as.factor(wind) + factor(magn) - 1,
family="binomial", data=shuttle)
summary(fit)$coef
exp(coef(fit))
？confint
?confint
cbind(OddsRatio = coef(fit), confint(fit))
coef(fit)
odds <- exp(summary(fit)$coef)
odds[1]/odds[2]
fit2 <- glm(I(1 - newUse) ~ as.factor(wind) - 1, data=shuttle, family="binomial")
summary(fit2)$coef
summary(fit)$coef
library(MASS)
?shuttle
shuttle$newUse <- as.numeric(shuttle$use == "auto")
fit <- glm(newUse ~ as.factor(wind) - 1, data=shuttle, family="binomial")
odds <- exp(summary(fit)$coef)
odds[1]/odds[2]
summary(fit2)$coef
summary(fit)$coef
offset(10)
offset(10,2)
?offset
fit <- glm(count ~ as.factor(spray) + offset(log(count+1)),
family="poisson", data=InsectSprays)
fit2 <- glm(count ~ as.factor(spray) + offset(log(10)+log(count+1)),
family="poisson", data=InsectSprays)
summary(fit)$coef
summary(fit2)$coef
x <- -5 : 5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
knotPoint <- c(0)
spline <- sapply(knotPoint, function(knot) (x > knot) * (x - knot))
xMatrix <- cbind(1, x, spline)
fit <- lm(y ~ xMatrix - 1)
yhat <- predict(fit)
yhat
slope <- fit$coef[2] + fit$coef[3]
slope # 1.013
plot(x, y)
lines(x, yhat, col=2)
summary(fit)
spline <- sapply(knotPoint, function(knot) (x > knot) * (x - knot))
spline <- sapply(knotPoint, function(knot) (x > knot) * (x - knot))
xMatrix <- cbind(1, x, spline)
xMatrix <- cbind(1, x, spline)
xMatrix
lines(x, yhat, col=2)
plot(x, y)
lines(x, yhat, col=2)
lines(x, yhat, col=1)
lines(x, yhat, col=3)
attach(mtcars)
cor(mpg, wt) * sd(mpg)/sd(wt)
## [1] -5.344
detach(mtcars)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p=3/4)[[1]]
training = mixtures[inTrain,]
testing = mixtures[-inTrain,]
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) +
geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p=3/4)[[1]]
training <- adData[inTrain, ]
testing <- adData[-inTrain, ]
dim(adData) # 333 131
# head(adData)
set.seed(62433)
fitRf <- train(diagnosis ~ ., data=training, method="rf")
fitGBM <- train(diagnosis ~ ., data=training, method="gbm")
fitLDA <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(fitRf, testing)
predGBM <- predict(fitGBM, testing)
predLDA <- predict(fitLDA, testing)
pred <- data.frame(predRf, predGBM, predLDA, diagnosis=testing$diagnosis)
# Stack the predictions together using random forests ("rf")
fit <- train(diagnosis ~., data=pred, method="rf")
predFit <- predict(fit, testing)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGBM, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLDA, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(predFit, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
set.seed(3523)
library(AppliedPredictiveModeling)
library(elasticnet)
data(concrete)
inTrain <- createDataPartition(concrete$CompressiveStrength,
p=3/4)[[1]]
training <- concrete[inTrain, ]
testing <- concrete[-inTrain, ]
set.seed(233)
fit <- train(CompressiveStrength ~ ., data=training, method="lasso")
fit
plot.enet(fit$finalModel, xvar="penalty", use.color=T) # Cement
?bats
??bats
install_from_swirl("Regression Models")
library(swirl)
library(swirl)
install.packages("swirl")
library("swirl", lib.loc="~/R/win-library/3.1")
install_course_zip("~/Downloads/swirl_courses-master.zip", multi=TRUE)
install_course_zip("C:/Users/YourDream/Downloads/swirl_courses-master.zip", multi=TRUE)
swirl()
plot(child~parent, galton)
plot(jitter(child,4)~parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regline)
summary(regrline)
lm(child~parent)
lm(child~parent,data = galton)
fit <- lm(child ~ parent, galton)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
ols.slope <- fit$coef[2]
lhs-rhs
fit <- lm(child ~ parent, galton)
all.equal(lhs,rhs)
fit <- lm(child ~ parent, galton)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- ols.slope * ols.ic
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varRes+varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residual)
mean(efit$residuals)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor()
cov(efit$residuals, attenu$mag)
cor(gpa_nor,gch_nor)
s
s
s
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent)
fit <- lm(child ~ parent,galton)
fit <- lm(child ~ parent,galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
deviance(fit)/(n-2)
sqrt(deviance(fit)/(n-2))
sqrt(deviance(fit)/(n-2))
"mu <- mean(galton$child)
""
mu <- mean(galton$child)
sTot <- galton$child - mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sTot <- galton$child - mean(galton$child)
sRes <- deviance(fit)
1 - sRes/sTot
summary(fit)$r.squared
cor()
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth",trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
?par
?pch
#Question 1.
Vector <- c(2/7,3/7,6/7)
q1_1 <- c(.954, .728, -.682);
q1_2 <- c(1.125, .500, -.625);
q1_3 <- c(.702, -.702, .117);
q1_4 <- c(-.286, .-.429, .857);
Vector %*% t(q1_1)
Vector <- c(2/7,3/7,6/7)
q1_1 <- c(.954, .728, -.682);
q1_2 <- c(1.125, .500, -.625);
q1_3 <- c(.702, -.702, .117);
q1_4 <- c(-.286, -.429, .857);
Vector %*% t(q1_1)
t(Vector) %*% q1_1
Vector
#Question 1.
Vector <- c(2/7,3/7,6/7)
q1_1 <- c(.954, .728, -.682);
q1_2 <- c(1.125, .500, -.625);
q1_3 <- c(.702, -.702, .117);
q1_4 <- c(-.286, -.429, .857);
t(Vector) %*% q1_1
t(Vector) %*% q1_2
t(Vector) %*% q1_3
t(Vector) %*% q1_4
Vector %*% q1_1
sqrt(sum(Vector^2))
sqrt(sum(q1_1^2))
sqrt(sum(q1_2^2))
sqrt(sum(q1_3^2))
sqrt(sum(q1_4^2))
q3_1 <- c(1,1)
q3_2 <- c(2,2)
q3_3 <- c(3,4)
M <- rbind(q3_1, q3_2, q3_3)
squareMatrix <- t(M) %*% M
squareMatrix
M
Vector <- c(1, 2, 3)
q4_1 <- c(-3, -2, 5);
q4_2 <- c(-1, -1, 1);
q4_3 <- c(1, 1/2, 1/3);
q4_4 <- c(2, -3, 1);
Vector %*% q4_1
Vector %*% q4_2
Vector %*% q4_3
Vector %*% q4_4
Vector <- c(2/7,3/7,6/7)
q1_1 <- c(-.937, .312, .156);
q1_2 <- c(.975, .700, -.675);
q1_3 <- c(2.250, -.500, -.750);
q1_4 <- c(1.125, .500, -.625);
Vector %*% q1_1
Vector %*% q1_2
Vector %*% q1_3
Vector %*% q1_4
sqrt(sum(Vector^2))
sqrt(sum(q1_1^2))
sqrt(sum(q1_2^2))
sqrt(sum(q1_3^2))
sqrt(sum(q1_4^2))
library(caret)
library(randomForest)
setwd('E:/Project/feature')
rawdata <- read.csv('ProcessedData.csv', header = TRUE, sep = ',')
data <- rawdata;
for(i in c(2:ncol(rawdata)-1)) {data[,i] = as.numeric(as.character(rawdata[,i]))}
featuresnames <- colnames(data)[-(1:1)]
features <- data[featuresnames]
set.seed(5188)
xdata <- createDataPartition(y=features$classe, p=3/4, list=FALSE )
training <- features[xdata,]
testing <- features[-xdata,]
rf_model  <- randomForest(classe ~ ., training, ntree=500, mtry=32)
training_pred <- predict(rf_model, training)
print(confusionMatrix(training_pred, training$classe))
testing_pred <- predict(rf_model, testing)
print(confusionMatrix(testing_pred, testing$classe))
for(i in c(2:ncol(rawdata)-1)) {data[,i] = as.numeric(as.character(rawdata[,i]))}
options (warn=-1)
